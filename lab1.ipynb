{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 120386,
     "databundleVersionId": 14398636,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv(\"/kaggle/input/mai-ml-lab-1-fiit-2025/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/mai-ml-lab-1-fiit-2025/test.csv\")\n",
    "\n",
    "print(\"Было строк в train:\", len(train))\n",
    "\n",
    "good_mask = (train['RiskScore'] >= 0) & (train['RiskScore'] <= 100)\n",
    "train = train[good_mask]\n",
    "\n",
    "print(\"Стало строк после очистки:\", len(train))\n",
    "print(\"RiskScore — min:\", train['RiskScore'].min(), \"max:\", train['RiskScore'].max())\n",
    "\n",
    "print(\"Размер датасета:\", train.shape)\n",
    "train.head()"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "train.info()\ntrain.describe(include='all')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "train[\"ApplicationDate\"] = pd.to_datetime(train[\"ApplicationDate\"])\ntrain.isna().sum().sort_values(ascending=False)",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(10,5))\nsns.histplot(train[\"RiskScore\"], kde=True, bins=40)\nplt.title(\"Распределение RiskScore\")\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "num_features = [\n    \"Age\", \"AnnualIncome\", \"CreditScore\", \"LoanAmount\",\n    \"LoanDuration\", \"MonthlyDebtPayments\", \"DebtToIncomeRatio\",\n    \"NetWorth\"\n]\n\ntrain[num_features].hist(figsize=(14, 10), bins=30)\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "features_to_plot = [\n    \"CreditScore\", \"AnnualIncome\", \"LoanAmount\",\n    \"DebtToIncomeRatio\", \"MonthlyDebtPayments\", \"NetWorth\"\n]\n\nplt.figure(figsize=(14, 10))\nfor i, feat in enumerate(features_to_plot, 1):\n    plt.subplot(2, 3, i)\n    sns.scatterplot(x=train[feat], y=train[\"RiskScore\"], alpha=0.5)\n    plt.title(f\"{feat} vs RiskScore\")\nplt.tight_layout()\nplt.show()\n",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(16, 12))\ncorr = train.corr(numeric_only=True)\nsns.heatmap(corr, cmap=\"coolwarm\", annot=False)\nplt.title(\"Correlation Matrix\")\nplt.show()\n\ncorr[\"RiskScore\"].sort_values(ascending=False).head(15)\n",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Разведочный анализ данных показал, что признаки в датасете в большинстве своём слабо коррелируют друг с другом и практически не имеют линейной зависимости с целевой переменной RiskScore. В данных присутствует значительное количество пропусков, особенно в ключевых финансовых характеристиках, что снижает качество статистических связей и влияет на корректность корреляционного анализа. Распределение RiskScore выглядит почти равномерным и не демонстрирует выраженной зависимости от входных признаков, что может указывать на его синтетическую природу.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nnumeric_cols = train.select_dtypes(include=['float64', 'int64']).columns\n\nz_scaler = StandardScaler()\ndf_zscore = train.copy()\ndf_zscore[numeric_cols] = z_scaler.fit_transform(train[numeric_cols])\n\nprint(\"Z-score normalized data (первые 5 строк):\")\ndisplay(df_zscore.head())\n\nmm_scaler = MinMaxScaler()\ndf_minmax = train.copy()\ndf_minmax[numeric_cols] = mm_scaler.fit_transform(train[numeric_cols])\n\nprint(\"Min-Max normalized data (первые 5 строк):\")\ndisplay(df_minmax.head())\n",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n\nclass MyLinearRegression:\n    def __init__(self, lambda_reg=1e-5):\n        self.weights = None\n        self.lambda_reg = lambda_reg\n       \n    def fit(self, X, y, method=\"normal\", lr=0.01, iters=2000, batch_size=32):\n        X = np.nan_to_num(X)\n        y = np.nan_to_num(y)\n        m, n = X.shape\n        X_b = np.hstack([np.ones((m, 1)), X])\n       \n        if method == \"normal\":\n            I = np.eye(n + 1)\n            I[0, 0] = 0\n            reg_matrix = X_b.T @ X_b + self.lambda_reg * I\n            try:\n                self.weights = np.linalg.solve(reg_matrix, X_b.T @ y)\n            except:\n                self.weights = np.linalg.pinv(reg_matrix) @ (X_b.T @ y)\n           \n        elif method == \"gd\":\n            self.weights = np.zeros(n + 1)\n            for _ in range(iters):\n                y_pred = X_b @ self.weights\n                grad = (2 / m) * X_b.T @ (y_pred - y)\n                self.weights -= lr * grad\n               \n        elif method == \"sgd\":\n            self.weights = np.zeros(n + 1)\n            for epoch in range(iters):\n                lr_epoch = lr / (1 + 0.001 * epoch)\n                indices = np.random.permutation(m)\n                X_b_shuf = X_b[indices]\n                y_shuf = y[indices]\n                for i in range(0, m, batch_size):\n                    X_batch = X_b_shuf[i:i+batch_size]\n                    y_batch = y_shuf[i:i+batch_size]\n                    grad = 2 * X_batch.T @ (X_batch @ self.weights - y_batch) / len(X_batch)\n                    self.weights -= lr_epoch * grad\n                   \n    def predict(self, X):\n        X = np.nan_to_num(X)  # защита и здесь!\n        X_b = np.hstack([np.ones((X.shape[0], 1)), X])\n        return X_b @ self.weights\n\ndf = train.copy()\nif 'ApplicationDate' in df.columns:\n    date = pd.to_datetime(df['ApplicationDate'], errors='coerce')\n    df['app_month'] = date.dt.month.fillna(0)\n    df['app_weekday'] = date.dt.weekday.fillna(0)\n    df['app_is_weekend'] = (date.dt.weekday >= 5).astype(int).fillna(0)\n    df = df.drop('ApplicationDate', axis=1, errors='ignore')\n\n\neps = 1\nif all(c in df.columns for c in ['CreditScore', 'Income']):\n    df['credit_income_ratio'] = df['CreditScore'] / (df['Income'] + eps)\nif all(c in df.columns for c in ['Debt', 'Income']):\n    df['dti'] = df['Debt'] / (df['Income'] + eps)\nif all(c in df.columns for c in ['LoanAmount', 'Income']):\n    df['pti'] = df['LoanAmount'] / (df['Income'] + eps)\nif 'Income' in df.columns:\n    df['log_income'] = np.log1p(df['Income'])\nif 'Age' in df.columns:\n    df['age_sq'] = df['Age'] ** 2\nif 'CreditScore' in df.columns:\n    df['credit_sq'] = df['CreditScore'] ** 2\n\ny_raw = pd.to_numeric(df['RiskScore'], errors='coerce')\ny = y_raw.fillna(y_raw.median() if not y_raw.isna().all() else 0).values\n\nX = df.drop(columns=['RiskScore'], errors='ignore')\n\ncat_cols = X.select_dtypes(include=['object', 'category']).columns\nfor col in cat_cols:\n    top = X[col].value_counts().head(15).index\n    X[col] = X[col].where(X[col].isin(top), 'Other')\n\nX = pd.get_dummies(X, drop_first=True)\n\nX = X.replace([np.inf, -np.inf], np.nan)\nX = X.fillna(X.median(numeric_only=True))\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nX_train_scaled = np.nan_to_num(X_train_scaled, nan=0.0, posinf=0.0, neginf=0.0)\nX_test_scaled = np.nan_to_num(X_test_scaled, nan=0.0, posinf=0.0, neginf=0.0)\n\nmodel_my = MyLinearRegression(lambda_reg=1e-5)\nmodel_my.fit(X_train_scaled, y_train, method=\"normal\")\npred_my = model_my.predict(X_test_scaled)\n\nprint(f\"Моя модель (нормальное ур.) MSE: {mean_squared_error(y_test, pred_my):.4f}\")\nprint(f\"Моя модель R²: {r2_score(y_test, pred_my):.6f}\")\n\nmodel_gd = MyLinearRegression()\nmodel_gd.fit(X_train_scaled, y_train, method=\"gd\", lr=0.05, iters=15000)\nprint(f\"Моя GD MSE: {mean_squared_error(y_test, model_gd.predict(X_test_scaled)):.4f}\")\n\nsk = LinearRegression()\nsk.fit(X_train_scaled, y_train)\npred_sk = sk.predict(X_test_scaled)\nprint(f\"\\nsklearn MSE: {mean_squared_error(y_test, pred_sk):.4f}\")\nprint(f\"sklearn R²:  {r2_score(y_test, pred_sk):.6f}\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from sklearn.model_selection import KFold\nimport numpy as np\n\ndef k_fold_cv(X, y, k=5):\n    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n    mse_scores = []\n\n    for train_index, test_index in kf.split(X):\n        X_train_cv, X_test_cv = X[train_index], X[test_index]\n        y_train_cv, y_test_cv = y[train_index], y[test_index]\n\n        model = MyLinearRegression()\n        model.fit(X_train_cv, y_train_cv, method=\"normal\")\n        y_pred_cv = model.predict(X_test_cv)\n        mse_scores.append(mean_squared_error(y_test_cv, y_pred_cv))\n\n    return np.mean(mse_scores), np.std(mse_scores)\n\nmean_mse, std_mse = k_fold_cv(X_train, y_train, k=5)\nprint(f\"K-Fold CV (k=5) MSE: {mean_mse:.4f} ± {std_mse:.4f}\")\n\ndef loo_cv(X, y):\n    n_samples = X.shape[0]\n    mse_scores = []\n\n    for i in range(n_samples):\n        X_train_loo = np.delete(X, i, axis=0)\n        y_train_loo = np.delete(y, i, axis=0)\n        X_test_loo = X[i:i+1]\n        y_test_loo = y[i:i+1]\n\n        model = MyLinearRegression()\n        model.fit(X_train_loo, y_train_loo, method=\"normal\")\n        y_pred_loo = model.predict(X_test_loo)\n        mse_scores.append((y_test_loo - y_pred_loo)**2)\n\n    mse_scores = np.array(mse_scores).flatten()\n    return np.mean(mse_scores), np.std(mse_scores)\n\nmean_mse_loo, std_mse_loo = loo_cv(X_train, y_train)\nprint(f\"LOO CV MSE: {mean_mse_loo:.4f} ± {std_mse_loo:.4f}\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nfrom sklearn.metrics import mean_squared_error as mse_sklearn\n\ndef mean_squared_error_manual(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    \n    if y_true.shape != y_pred.shape:\n        raise ValueError(\"y_true и y_pred должны иметь одинаковую форму\")\n    \n    mse = np.mean((y_true - y_pred) ** 2)\n    return mse",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "y_pred = model_normal.predict(X_test)\n\nmse_manual = mean_squared_error_manual(y_test, y_pred)\nprint(\"Manual MSE:\", mse_manual)\n\nmse_skl = mse_sklearn(y_test, y_pred)\nprint(\"Sklearn MSE:\", mse_skl)\n\nprint(\"Разница:\", abs(mse_manual - mse_skl))",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nfrom sklearn.metrics import mean_absolute_error as mae_sklearn\n\ndef mean_absolute_error_manual(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    \n    if y_true.shape != y_pred.shape:\n        raise ValueError(\"y_true и y_pred должны иметь одинаковую форму\")\n    \n    mae = np.mean(np.abs(y_true - y_pred))\n    return mae",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "y_pred = model_normal.predict(X_test)\n\nmae_manual = mean_absolute_error_manual(y_test, y_pred)\nprint(\"Manual MAE:\", mae_manual)\n\nmae_skl = mae_sklearn(y_test, y_pred)\nprint(\"Sklearn MAE:\", mae_skl)\n\nprint(\"Разница:\", abs(mae_manual - mae_skl))",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nfrom sklearn.metrics import r2_score as r2_sklearn\n\ndef r2_score_manual(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    if y_true.shape != y_pred.shape:\n        raise ValueError(\"y_true и y_pred должны иметь одинаковую форму\")\n\n    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n    ss_res = np.sum((y_true - y_pred) ** 2)\n    \n    r2 = 1 - ss_res / ss_total\n    return r2",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "y_pred = model_normal.predict(X_test)\n\nr2_manual = r2_score_manual(y_test, y_pred)\nprint(\"Manual R²:\", r2_manual)\n\nr2_skl = r2_sklearn(y_test, y_pred)\nprint(\"Sklearn R²:\", r2_skl)\n\nprint(\"Разница:\", abs(r2_manual - r2_skl))",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from sklearn.metrics import mean_absolute_percentage_error as mape_sklearn\n\ndef mean_absolute_percentage_error_manual_safe(y_true, y_pred, eps=1e-2):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    \n    if y_true.shape != y_pred.shape:\n        raise ValueError(\"y_true и y_pred должны иметь одинаковую форму\")\n\n    mask = np.abs(y_true) > eps\n    if not np.any(mask):\n        raise ValueError(\"Все значения y_true слишком малы для вычисления MAPE\")\n    \n    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n    return mape",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "y_pred = model_normal.predict(X_test)\n\nmae_manual = mean_absolute_error_manual(y_test, y_pred)\nprint(\"Manual MAE:\", mae_manual)\n\nmae_skl = mae_sklearn(y_test, y_pred)\nprint(\"Sklearn MAE:\", mae_skl)\n\nprint(\"Разница:\", abs(mae_manual - mae_skl))",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nfrom sklearn.metrics import r2_score as r2_sklearn\n\ndef r2_score_manual(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    if y_true.shape != y_pred.shape:\n        raise ValueError(\"y_true и y_pred должны иметь одинаковую форму\")\n\n    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n    ss_res = np.sum((y_true - y_pred) ** 2)\n    \n    r2 = 1 - ss_res / ss_total\n    return r2",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "y_pred = model_normal.predict(X_test)\n\nr2_manual = r2_score_manual(y_test, y_pred)\nprint(\"Manual R²:\", r2_manual)\n\nr2_skl = r2_sklearn(y_test, y_pred)\nprint(\"Sklearn R²:\", r2_skl)\n\nprint(\"Разница:\", abs(r2_manual - r2_skl))",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from sklearn.metrics import mean_absolute_percentage_error as mape_sklearn\n\ndef mean_absolute_percentage_error_manual_safe(y_true, y_pred, eps=1e-2):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    \n    if y_true.shape != y_pred.shape:\n        raise ValueError(\"y_true и y_pred должны иметь одинаковую форму\")\n\n    mask = np.abs(y_true) > eps\n    if not np.any(mask):\n        raise ValueError(\"Все значения y_true слишком малы для вычисления MAPE\")\n    \n    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n    return mape",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "mape_manual_safe = mean_absolute_percentage_error_manual_safe(y_test, y_pred)\nprint(\"Manual safe MAPE (%):\", mape_manual_safe)\n\n# Для sklearn можно использовать тот же подход:\ny_test_safe = y_test[np.abs(y_test) > 1e-2]\ny_pred_safe = y_pred[np.abs(y_test) > 1e-2]\nmape_skl_safe = mape_sklearn(y_test_safe, y_pred_safe) * 100\nprint(\"Sklearn safe MAPE:\", mape_skl_safe)\n\nprint(\"Разница:\", abs(r2_manual - r2_skl))",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "test = pd.read_csv(\"/kaggle/input/mai-ml-lab-1-fiit-2025/test.csv\")\ntest_ids = test[\"ID\"]\n\ndf_test = test.copy()\n\nif 'ApplicationDate' in df_test.columns:\n    date = pd.to_datetime(df_test['ApplicationDate'], errors='coerce')\n    df_test['app_month'] = date.dt.month.fillna(0)\n    df_test['app_weekday'] = date.dt.weekday.fillna(0)\n    df_test['app_is_weekend'] = (date.dt.weekday >= 5).astype(int).fillna(0)\n    df_test = df_test.drop('ApplicationDate', axis=1, errors='ignore')\n\neps = 1\nif all(c in df_test.columns for c in ['CreditScore', 'Income']):\n    df_test['credit_income_ratio'] = df_test['CreditScore'] / (df_test['Income'] + eps)\nif all(c in df_test.columns for c in ['Debt', 'Income']):\n    df_test['dti'] = df_test['Debt'] / (df_test['Income'] + eps)\nif all(c in df_test.columns for c in ['LoanAmount', 'Income']):\n    df_test['pti'] = df_test['LoanAmount'] / (df_test['Income'] + eps)\nif 'Income' in df_test.columns:\n    df_test['log_income'] = np.log1p(df_test['Income'])\nif 'Age' in df_test.columns:\n    df_test['age_sq'] = df_test['Age'] ** 2\nif 'CreditScore' in df_test.columns:\n    df_test['credit_sq'] = df_test['CreditScore'] ** 2\n\ncat_cols = df_test.select_dtypes(include=['object', 'category']).columns\nfor col in cat_cols:\n    if col in X.columns:\n        top_cats = X[col].value_counts().head(15).index\n        df_test[col] = df_test[col].where(df_test[col].isin(top_cats), 'Other')\n\nX_submit = df_test.drop(columns=['ID'], errors='ignore')\nX_submit = pd.get_dummies(X_submit, drop_first=True)\nX_submit = X_submit.reindex(columns=X.columns, fill_value=0)\nX_submit = X_submit.fillna(X.median(numeric_only=True))\nX_submit_scaled = scaler.transform(X_submit)\nX_submit_scaled = np.nan_to_num(X_submit_scaled, nan=0.0, posinf=0.0, neginf=0.0)\n\ny_pred_submit = model_my.predict(X_submit_scaled)\n\nsubmission = pd.DataFrame({\n    \"ID\": test_ids,\n    \"RiskScore\": y_pred_submit.flatten()\n})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv готов)\nprint(f\"Предсказания: min={y_pred_submit.min():.2f}, max={y_pred_submit.max():.2f}, mean={y_pred_submit.mean():.2f}\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
